{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "23dfcf66",
   "metadata": {},
   "source": [
    "# What is this?\n",
    "Now that I have thousands of sets entered into this application over the last year, might as well analyze it a bit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171d7250",
   "metadata": {},
   "source": [
    "# 1. Getting the data in a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f024068",
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import os \n",
    "ddb = boto3.resource('dynamodb')\n",
    "\n",
    "sets_table_name = os.getenv(\"GAINS_IQ_SETS_TABLE_NAME\")\n",
    "target_user = os.getenv(\"GAINS_IQ_TARGET_USERNAME\")\n",
    "\n",
    "sets_table = ddb.Table(sets_table_name)\n",
    "\n",
    "scan_kwargs = {\n",
    "    'FilterExpression': 'username = :u',\n",
    "    'ExpressionAttributeValues': {\n",
    "        ':u': target_user\n",
    "    }\n",
    "}\n",
    "\n",
    "\n",
    "response = sets_table.scan(**scan_kwargs)\n",
    "raw_set_data = response['Items']\n",
    "\n",
    "while 'LastEvaluatedKey' in response:\n",
    "    response = sets_table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])\n",
    "    raw_set_data.extend(response['Items'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1130249",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_table_name = os.getenv(\"GAINS_IQ_WEIGHT_TABLE_NAME\")\n",
    "weight_table = ddb.Table(weight_table_name)\n",
    "scan_kwargs = {\n",
    "    'FilterExpression': 'username = :u',\n",
    "    'ExpressionAttributeValues': {\n",
    "        ':u': target_user\n",
    "    }\n",
    "}\n",
    "\n",
    "response = weight_table.scan(**scan_kwargs)\n",
    "raw_weight_data = response['Items']\n",
    "\n",
    "while 'LastEvaluatedKey' in response:\n",
    "    response = weight_table.scan(ExclusiveStartKey=response['LastEvaluatedKey'])\n",
    "    raw_weight_data.extend(response['Items'])\n",
    "raw_weight_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db44229",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import re\n",
    "\n",
    "# To handle \"16 or above\" and similar rep entries\n",
    "def clean_reps(rep_string):\n",
    "    if pd.isna(rep_string) or rep_string is None:\n",
    "        return 0\n",
    "    match = re.search(r'\\d+', str(rep_string)) \n",
    "    if match:\n",
    "        return int(match.group(0))\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "df_sets = pd.DataFrame(raw_set_data)\n",
    "df_set = df_sets.drop(columns=['userId', 'username', 'workoutId']) # workoutId is meaningless and this is only ran on a single user at a time\n",
    "\n",
    "numerical_fields = ['sets', 'timestamp', 'weight']\n",
    "df_sets[numerical_fields] = df_sets[numerical_fields].astype(float)\n",
    "\n",
    "# categorical feature encoding\n",
    "df_sets['exercise_idx'] = df_sets['exercise'].astype('category').cat.codes\n",
    "df_sets['modulation_idx'] = df_sets['weight_modulation'].astype('category').cat.codes\n",
    "\n",
    "df_sets['reps'] = df_sets['reps'].apply(clean_reps)\n",
    "df_sets['reps'] = df_sets['reps'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ee04b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# More complex feature engineering \n",
    "\n",
    "# Something important is how far into a workout a set took place. We can find this by grouping sets into workouts and then calculating from there\n",
    "# each workout is at least 8 hours apart (probably), so we can use that to do the grouping\n",
    "\n",
    "# 12 hours in seconds\n",
    "NEW_WORKOUT_THRESHOLD_SEC = 8 * 60 * 60\n",
    "\n",
    "df_sets = df_sets.sort_values(by='timestamp').reset_index(drop=True)\n",
    "\n",
    "df_sets['time_diff'] = df_sets['timestamp'].diff().fillna(NEW_WORKOUT_THRESHOLD_SEC + 1)\n",
    "df_sets['is_new_workout'] = df_sets['time_diff'] > NEW_WORKOUT_THRESHOLD_SEC\n",
    "\n",
    "# Create the virtual workout ID by cumulatively summing the 'is_new_workout' column.\n",
    "# This assigns a unique, incremental ID (0, 1, 2, ...) to each hypothesized workout\n",
    "df_sets['virtual_workout_id'] = df_sets['is_new_workout'].cumsum()\n",
    "\n",
    "# Now, calculate time elapsed using the new 'virtual_workout_id'\n",
    "grouped = df_sets.groupby('virtual_workout_id')\n",
    "first_timestamp = grouped['timestamp'].transform('min')\n",
    "df_sets['time_elapsed_sec'] = df_sets['timestamp'] - first_timestamp\n",
    "df_sets['time'] = pd.to_datetime(df_sets['timestamp'], unit='s')\n",
    "df_sets['weight'] = df_sets['weight'].astype(float)\n",
    "df_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "874a5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Making a DataFrame for weight data\n",
    "df_bw = pd.DataFrame(raw_weight_data)\n",
    "df_bw['bodyweight'] = df_bw['weight'].astype(float) \n",
    "df_bw['timestamp_bw'] = df_bw['timestamp'].astype(float) \n",
    "df_bw['time'] = pd.to_datetime(df_bw['timestamp_bw'], unit='s')\n",
    "df_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a89f1afc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merging set and weight data together\n",
    "df_merged = pd.merge_asof(\n",
    "    df_sets.sort_values('time'),\n",
    "    df_bw.sort_values('time'), \n",
    "    left_on='time', \n",
    "    right_on='time', \n",
    "    direction='backward' # Finds the nearest preceding or exact match\n",
    ")\n",
    "column_mapping = {\n",
    "    # Core Workout Data (Renamed for clarity)\n",
    "    'timestamp_x': 'set_timestamp', # Keep the set's timestamp\n",
    "    'weight_x': 'set_weight_lb',   # Keep the set's weight\n",
    "    'reps': 'reps',\n",
    "    'sets': 'sets',\n",
    "    'exercise': 'exercise_name',\n",
    "    'weight_modulation': 'modulation_name',\n",
    "    'bodyweight': 'bodyweight_lb', # The integrated bodyweight\n",
    "    'exercise_idx': 'exercise_idx',\n",
    "    'modulation_idx': 'modulation_idx',\n",
    "    'virtual_workout_id': 'virtual_workout_id',\n",
    "    'time_elapsed_sec': 'time_elapsed_sec',\n",
    "}\n",
    "\n",
    "columns_to_keep = list(column_mapping.keys())\n",
    "df_clean = df_merged[columns_to_keep].rename(columns=column_mapping).copy()\n",
    "\n",
    "df_clean['set_weight_lb'] = df_clean['set_weight_lb'].astype(float)\n",
    "df_clean['bodyweight_lb'] = df_clean['bodyweight_lb'].astype(float)\n",
    "\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e78be03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding in day of the week, using sin/cos the embed the cyclical nature\n",
    "import numpy as np \n",
    "df_clean['datetime'] = pd.to_datetime(df_clean['set_timestamp'], unit='s')\n",
    "\n",
    "# Hour of Day (0 to 23)\n",
    "df_clean['hour'] = df_clean['datetime'].dt.hour\n",
    "HOURS_IN_DAY = 24\n",
    "\n",
    "# Day of Week (0=Monday, 6=Sunday)\n",
    "df_clean['day_of_week'] = df_clean['datetime'].dt.dayofweek\n",
    "DAYS_IN_WEEK = 7\n",
    "\n",
    "# Hour Sin/Cos\n",
    "df_clean['hour_sin'] = np.sin(2 * np.pi * df_clean['hour'] / HOURS_IN_DAY)\n",
    "df_clean['hour_cos'] = np.cos(2 * np.pi * df_clean['hour'] / HOURS_IN_DAY)\n",
    "\n",
    "# Day of Week Sin/Cos\n",
    "df_clean['day_of_week_sin'] = np.sin(2 * np.pi * df_clean['day_of_week'] / DAYS_IN_WEEK)\n",
    "df_clean['day_of_week_cos'] = np.cos(2 * np.pi * df_clean['day_of_week'] / DAYS_IN_WEEK)\n",
    "\n",
    "# (The sine/cosine columns carry the information, and the original timestamp is also kept)\n",
    "df_clean = df_clean.drop(columns=['datetime', 'hour', 'day_of_week'], errors='ignore')\n",
    "df_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "116917e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "\n",
    "feature_columns = [\n",
    "    'set_timestamp',\n",
    "    'hour_sin',\n",
    "    'hour_cos',\n",
    "    'day_of_week_sin',\n",
    "    'day_of_week_cos',\n",
    "    'time_elapsed_sec',\n",
    "    'sets',\n",
    "    'reps',\n",
    "    'set_weight_lb',\n",
    "    'exercise_idx',    \n",
    "    'modulation_idx',\n",
    "    'bodyweight_lb',\n",
    "    'virtual_workout_id' \n",
    "]\n",
    "\n",
    "data_numpy = df_clean[feature_columns].values\n",
    "raw_tensor = torch.tensor(data_numpy, dtype=torch.float32)\n",
    "raw_tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1461c0",
   "metadata": {},
   "source": [
    "# Seeing what we can derive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3730b064",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "812d1ef7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
